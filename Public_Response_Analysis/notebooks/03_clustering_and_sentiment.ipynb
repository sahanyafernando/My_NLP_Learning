{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahanyafernando/My_NLP_Learning/blob/main/Project_01_Public_Responce_Analysis/notebooks/Project_01_Public_Response_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load preprocessing artifacts\nLoads outputs saved by `01_data_loading_and_preprocessing.ipynb`. Run that notebook first if this file is missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pickle, pathlib\n",
        "# Update this path if your project lives elsewhere in Drive\n",
        "artifacts_root = pathlib.Path(\"/content/drive/MyDrive/My_NLP_Learning/Public_Response_Analysis\")\n",
        "artifacts_path = artifacts_root / \"artifacts/preprocessing_outputs.pkl\"\n",
        "if artifacts_path.exists():\n",
        "    with open(artifacts_path, \"rb\") as f:\n",
        "        artifacts = pickle.load(f)\n",
        "    df = artifacts[\"df\"]\n",
        "    one_hot_vectorizer = artifacts[\"one_hot_vectorizer\"]\n",
        "    one_hot_matrix = artifacts[\"one_hot_matrix\"]\n",
        "    bow_vectorizer = artifacts[\"bow_vectorizer\"]\n",
        "    bow_matrix = artifacts[\"bow_matrix\"]\n",
        "    tfidf_vectorizer = artifacts[\"tfidf_vectorizer\"]\n",
        "    tfidf_matrix = artifacts[\"tfidf_matrix\"]\n",
        "    cooccurrence_vectorizer = artifacts[\"cooccurrence_vectorizer\"]\n",
        "    cooccurrence_matrix = artifacts[\"cooccurrence_matrix\"]\n",
        "    print(\"Loaded preprocessing outputs from artifacts/preprocessing_outputs.pkl\")\n",
        "else:\n",
        "    print(\"Run 01_data_loading_and_preprocessing.ipynb to generate artifacts first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply K-means Clustering\n",
        "\n",
        "\n",
        "Apply K-means clustering to the TF-IDF matrix to group documents into clusters.\n"
      ],
      "metadata": {
        "id": "dHw8iKmbci5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Determine an appropriate number of clusters\n",
        "n_clusters = 5 # Using the same number of topics as NMF for consistency\n",
        "\n",
        "# Initialize a KMeans model\n",
        "kmeans_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10) # n_init is set to 10 for explicit initialization runs\n",
        "\n",
        "# Fit the KMeans model to the tfidf_matrix\n",
        "kmeans_model.fit(tfidf_matrix)\n",
        "\n",
        "# Add the generated cluster labels to the DataFrame df as a new column\n",
        "df['kmeans_cluster_label'] = kmeans_model.labels_\n",
        "\n",
        "# Print the count of documents per cluster\n",
        "print(\"Count of documents per K-means cluster:\")\n",
        "print(df['kmeans_cluster_label'].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejFCGNTjcyb-",
        "outputId": "f2517aae-291d-49ba-9bfb-3cb64a479a48"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of documents per K-means cluster:\n",
            "kmeans_cluster_label\n",
            "0    12\n",
            "1    21\n",
            "2    27\n",
            "3    17\n",
            "4    23\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpret K-means Clusters\n",
        "\n",
        "Interpret the clusters generated by the K-means model by identifying the most representative words for each cluster."
      ],
      "metadata": {
        "id": "-k9RnNGTp_fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "n_top_words_cluster = 10\n",
        "\n",
        "print(\"\\nTop words for each K-means cluster:\")\n",
        "# The cluster centroids represent the average feature values for documents in that cluster\n",
        "for i, centroid in enumerate(kmeans_model.cluster_centers_):\n",
        "    print(f\"Cluster {i+1}:\")\n",
        "    # Sort words by their centroid weight in descending order\n",
        "    top_words_indices = centroid.argsort()[:-n_top_words_cluster - 1:-1]\n",
        "    top_words_cluster = [feature_names[j] for j in top_words_indices]\n",
        "    print(f\"{', '.join(top_words_cluster)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyWeomH-qnGp",
        "outputId": "ff3079de-8fb8-4686-de63-bb5e09e326eb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top words for each K-means cluster:\n",
            "Cluster 1:\n",
            "publictransport, prove, red, although, break, him, play, lead, raise, each\n",
            "Cluster 2:\n",
            "environmentallaws, current, educationpolicy, analysis, simply, generation, place, second, occur, specific\n",
            "Cluster 3:\n",
            "economicrelief, phone, face, officer, experience, ever, animal, political, market, hundred\n",
            "Cluster 4:\n",
            "increase, economicrelief, list, chance, publictransport, degree, kind, even, husband, different\n",
            "Cluster 5:\n",
            "healthcarereform, educationpolicy, despite, measure, seek, mrs, today, attention, table, ago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multilingual Sentiment Scoring\n",
        "\n",
        "Score sentiment polarity using tools like VADER (for English) and explore appropriate methods or custom lexicons for other languages (Spanish, French, German, Hindi), focusing on noise-tolerant preprocessing to enhance accuracy.\n"
      ],
      "metadata": {
        "id": "J4d4nzKMq7E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download VADER lexicon if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('sentiment/vader_lexicon')\n",
        "except LookupError:\n",
        "    nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize the VADER sentiment analyzer\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "print(\"VADER sentiment analyzer initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fInBSkOarGWW",
        "outputId": "d03f203b-ee08-4537-91d9-ae8c97bb421b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VADER sentiment analyzer initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlbEDktmhmgYLf9YCV02x/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}