{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahanyafernando/My_NLP_Learning/blob/main/Public_Response_Analysis/notebooks/06_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06 â€“ Extractive and Abstractive Summarization\n",
        "\n",
        "This notebook summarizes multilingual policy response posts using TextRank (extractive)\n",
        "and transformer-based models (BART/T5) for abstractive summaries on English text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle, pathlib\n",
        "\n",
        "artifacts_root = pathlib.Path(\"/content/drive/MyDrive/My_NLP_Learning/Public_Response_Analysis\")\n",
        "artifacts_path = artifacts_root / \"artifacts/preprocessing_outputs.pkl\"\n",
        "\n",
        "if artifacts_path.exists():\n",
        "    with open(artifacts_path, \"rb\") as f:\n",
        "        artifacts = pickle.load(f)\n",
        "    df = artifacts[\"df\"]\n",
        "    print(\"Loaded preprocessing artifacts and DataFrame.\")\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"Artifacts not found. Please run 01_data_loading_and_preprocessing.ipynb first \"\n",
        "        \"and execute the 'Save preprocessing artifacts' cell.\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extractive summarization with TextRank\n",
        "\n",
        "We apply a simple TextRank-style approach over English posts to extract the most\n",
        "representative sentences for each policy topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q summa\n",
        "\n",
        "from summa.summarizer import summarize\n",
        "\n",
        "english_df = df[df[\"language\"] == \"en\"]\n",
        "\n",
        "for topic in english_df[\"topic\"].unique():\n",
        "    subset = english_df[english_df[\"topic\"] == topic]\n",
        "    long_text = \"\\n\".join(subset[\"text\"].tolist())\n",
        "    print(f\"\\n===== Topic: {topic} =====\")\n",
        "    try:\n",
        "        summary = summarize(long_text, ratio=0.3)\n",
        "        print(\"Extractive summary:\")\n",
        "        print(summary)\n",
        "    except ValueError:\n",
        "        print(\"Not enough text for summarization.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abstractive summarization with BART/T5\n",
        "\n",
        "We use a pretrained transformer summarization pipeline (BART) on English text.\n",
        "For other languages, you can translate to English first or use multilingual T5 models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q transformers sentencepiece\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "sample_posts = english_df[\"text\"].head(5).tolist()\n",
        "for i, text in enumerate(sample_posts, start=1):\n",
        "    print(f\"\\n--- Post {i} ---\")\n",
        "    print(\"Original:\", text)\n",
        "    summary = summarizer(text, max_length=60, min_length=15, do_sample=False)[0][\"summary_text\"]\n",
        "    print(\"Abstractive summary:\", summary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNlbEDktmhmgYLf9YCV02x/",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
