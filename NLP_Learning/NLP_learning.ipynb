{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahanyafernando/My_NLP_Learning/blob/main/NLP_Learning/NLP_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration: Lowercasing, Stopword Removal, Tokenization and One-Hot Encoding"
      ],
      "metadata": {
        "id": "XDbvP_b8X4jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 01: Lowercasing, Stopword Removal and Tokenization"
      ],
      "metadata": {
        "id": "mPSQm_EqYg5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"text_classification.csv\")\n",
        "print(\"Original Dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "lAvlzd_fw9Ls",
        "outputId": "397c62bc-28e6-4c92-cd1d-d0920d6b4808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "                                        text  category\n",
            "0  The stock market rose by 300 points today   finance\n",
            "1   Manchester United won the football match    sports\n",
            "2  New research shows benefits of meditation    health\n",
            "3            The government passed a new law  politics\n",
            "4      Scientists discovered a new exoplanet   science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "cTWSWQLU52Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This outputs one colunm with its lower case form\n",
        "df[\"Lowercase_Pandas\"] = df[\"text\"].str.lower()\n",
        "print(df[[\"Lowercase_Pandas\"]].head())\n"
      ],
      "metadata": {
        "id": "QyiCOGHD6baN",
        "outputId": "984ea113-4b04-411d-c9f6-6cf15de6cbff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Lowercase_Pandas\n",
            "0  the stock market rose by 300 points today\n",
            "1   manchester united won the football match\n",
            "2  new research shows benefits of meditation\n",
            "3            the government passed a new law\n",
            "4      scientists discovered a new exoplanet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# if we want to get the 2 colunms with their lowercase form then\n",
        "df[\"text_lower\"] = df[\"text\"].str.lower()\n",
        "df[\"category_lower\"] = df[\"category\"].str.lower()\n",
        "print(df[[\"text_lower\", \"category_lower\"]].head())"
      ],
      "metadata": {
        "id": "05yefqak8oXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146a9fa0-a003-46b8-a6b2-268f98ed9878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  text_lower category_lower\n",
            "0  the stock market rose by 300 points today        finance\n",
            "1   manchester united won the football match         sports\n",
            "2  new research shows benefits of meditation         health\n",
            "3            the government passed a new law       politics\n",
            "4      scientists discovered a new exoplanet        science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using spaCy\n",
        "df = pd.read_csv(\"faq_dataset.csv\")\n",
        "\n",
        "def lowercase_spacy(text):\n",
        "  tokens = [token.text.lower() for token in nlp(text)]\n",
        "  return \" \".join(tokens)    # if we want we can add separate character like \" \"\n",
        "df[\"Lowercase_spaCy\"] = df[\"question\"].apply(lowercase_spacy)\n",
        "print(df[[\"Lowercase_spaCy\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dXHccJo_uld",
        "outputId": "2f2c7331-6508-4799-cc26-11a03b9d0af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Lowercase_spaCy\n",
            "0                  what is nlp ?\n",
            "1         who developed python ?\n",
            "2     what is a neural network ?\n",
            "3   what is sentiment analysis ?\n",
            "4  what is tokenization in nlp ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_word_nltk = set(stopwords.words(\"english\"))\n",
        "stop_words_spacy = nlp.Defaults.stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNuUFjEgG6n9",
        "outputId": "a5a0453d-4d06-4b2d-91c2-04b780d9699a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV\n",
        "df = pd.read_csv(\"text_classification.csv\")\n",
        "\n",
        "# Convert 'text' column to lowercase\n",
        "df[\"text_lower\"] = df[\"text\"].str.lower()\n",
        "\n",
        "# Using NLTK\n",
        "def remove_stopwords_nltk(text):\n",
        "  words = word_tokenize(text)\n",
        "  return \" \".join([word for word in words if word not in stop_word_nltk])\n",
        "df[\"No_Stopwords_NLTK\"] = df[\"text_lower\"].apply(remove_stopwords_nltk)\n",
        "print(df[[\"No_Stopwords_NLTK\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFf5mRvlI1R1",
        "outputId": "addd6aaa-0794-4ba4-89c3-c46afc090c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        No_Stopwords_NLTK\n",
            "0      stock market rose 300 points today\n",
            "1        manchester united football match\n",
            "2  new research shows benefits meditation\n",
            "3               government passed new law\n",
            "4     scientists discovered new exoplanet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoding**"
      ],
      "metadata": {
        "id": "EK5rkK7L624k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "YipVgZj16-MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using NLTK  tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "df[\"Tokenized_NLTK\"] = df[\"text_lower\"].apply(word_tokenize)\n",
        "print(df[\"Tokenized_NLTK\"].head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiRp1QZv7e6x",
        "outputId": "7baf0d96-1349-4e46-cb5b-1fcbc4b73686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [the, stock, market, rose, by, 300, points, to...\n",
            "1      [manchester, united, won, the, football, match]\n",
            "2     [new, research, shows, benefits, of, meditation]\n",
            "3               [the, government, passed, a, new, law]\n",
            "4          [scientists, discovered, a, new, exoplanet]\n",
            "Name: Tokenized_NLTK, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "df_onehot_nltk = pd.DataFrame(mlb.fit_transform(df[\"Tokenized_NLTK\"]), columns = mlb.classes_)\n",
        "print(\"- Using NLTK:\")\n",
        "print(df_onehot_nltk.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfZNb6GH9cDD",
        "outputId": "ba663ab6-b349-439e-93f4-8a7f1cd96de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Using NLTK:\n",
            "   300  a  benefits  by  discovered  exoplanet  football  government  law  \\\n",
            "0    1  0         0   1           0          0         0           0    0   \n",
            "1    0  0         0   0           0          0         1           0    0   \n",
            "2    0  0         1   0           0          0         0           0    0   \n",
            "3    0  1         0   0           0          0         0           1    1   \n",
            "4    0  1         0   0           1          1         0           0    0   \n",
            "\n",
            "   manchester  ...  points  research  rose  scientists  shows  stock  the  \\\n",
            "0           0  ...       1         0     1           0      0      1    1   \n",
            "1           1  ...       0         0     0           0      0      0    1   \n",
            "2           0  ...       0         1     0           0      1      0    0   \n",
            "3           0  ...       0         0     0           0      0      0    1   \n",
            "4           0  ...       0         0     0           1      0      0    0   \n",
            "\n",
            "   today  united  won  \n",
            "0      1       0    0  \n",
            "1      0       1    1  \n",
            "2      0       0    0  \n",
            "3      0       0    0  \n",
            "4      0       0    0  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Scikit-learn\n",
        "vectorizer = CountVectorizer()\n",
        "df_onehot_sklearn = pd.DataFrame(vectorizer.fit_transform(df[\"No_Stopwords_NLTK\"]).toarray(), columns = vectorizer.get_feature_names_out())\n",
        "print(\"- Using Scikit-learn:\")\n",
        "print(df_onehot_sklearn.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiMnd_3I96ET",
        "outputId": "b57c2127-0d47-493e-e898-0ec9e339c52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Using Scikit-learn:\n",
            "   300  benefits  discovered  exoplanet  football  government  law  \\\n",
            "0    1         0           0          0         0           0    0   \n",
            "1    0         0           0          0         1           0    0   \n",
            "2    0         1           0          0         0           0    0   \n",
            "3    0         0           0          0         0           1    1   \n",
            "4    0         0           1          1         0           0    0   \n",
            "\n",
            "   manchester  market  match  ...  new  passed  points  research  rose  \\\n",
            "0           0       1      0  ...    0       0       1         0     1   \n",
            "1           1       0      1  ...    0       0       0         0     0   \n",
            "2           0       0      0  ...    1       0       0         1     0   \n",
            "3           0       0      0  ...    1       1       0         0     0   \n",
            "4           0       0      0  ...    1       0       0         0     0   \n",
            "\n",
            "   scientists  shows  stock  today  united  \n",
            "0           0      0      1      1       0  \n",
            "1           0      0      0      0       1  \n",
            "2           0      1      0      0       0  \n",
            "3           0      0      0      0       0  \n",
            "4           1      0      0      0       0  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"processed_dataset.csv\", index = False)\n",
        "print(\"Preprocessing complete. Saved as processed_dataset.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0-Xpt0oGuPm",
        "outputId": "66e9ab82-be30-4581-b535-affa105d328c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing complete. Saved as processed_dataset.csv.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}