{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahanyafernando/My_NLP_Learning/blob/main/NLP_Learning/7_TextClassificationWithTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Demonstration: Text Classification using Transformers (Sentence Transformers)\n",
        "\n",
        "This notebook demonstrates text classification using **Sentence Transformers** for creating semantic embeddings, which are then used to train classification models. This approach captures semantic meaning better than traditional TF-IDF methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"sentiment_analysis.csv\", encoding='latin-1').sample(10, random_state=42)\n",
        "test_df = pd.read_csv(\"sentiment_analysis.csv\", encoding='latin-1')\n",
        "\n",
        "print(\"Dataset Loaded:\")\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Selecting relevant columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df[['review', 'sentiment']]\n",
        "test_df = test_df[['review', 'sentiment']]\n",
        "\n",
        "print(\"Selected columns:\")\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Standardizing labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standardize_sentiment(Sentiment):\n",
        "    if Sentiment in ['Positive', 'Extremely Positive']:\n",
        "        return 1\n",
        "    elif Sentiment in ['Negative', 'Extremely Negative']:\n",
        "        return 0\n",
        "    else:\n",
        "        return 2 # Neutral\n",
        "\n",
        "train_df['sentiment'] = train_df['sentiment'].apply(standardize_sentiment)\n",
        "test_df['sentiment'] = test_df['sentiment'].apply(standardize_sentiment)\n",
        "\n",
        "print(\"Standardized labels:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(train_df['sentiment'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Install Sentence Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Generate Sentence Embeddings using Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load a pre-trained sentence transformer model\n",
        "# This model creates 384-dimensional embeddings that capture semantic meaning\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "print(\"Sentence Transformer model loaded successfully!\")\n",
        "print(f\"Model embedding dimension: {model.get_sentence_embedding_dimension()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate embeddings for training data\n",
        "print(\"Generating embeddings for training data...\")\n",
        "train_embeddings = model.encode(train_df['review'].tolist(), show_progress_bar=True, batch_size=16)\n",
        "\n",
        "# Generate embeddings for test data\n",
        "print(\"\\nGenerating embeddings for test data...\")\n",
        "test_embeddings = model.encode(test_df['review'].tolist(), show_progress_bar=True, batch_size=16)\n",
        "\n",
        "print(f\"\\nTraining embeddings shape: {train_embeddings.shape}\")\n",
        "print(f\"Test embeddings shape: {test_embeddings.shape}\")\n",
        "print(f\"\\nSample embedding (first 10 dimensions): {train_embeddings[0][:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Prepare Training and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = train_embeddings\n",
        "X_test = test_embeddings\n",
        "Y_train = train_df['sentiment'].values\n",
        "Y_test = test_df['sentiment'].values\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n",
        "print(f\"\\nTraining label distribution:\")\n",
        "print(pd.Series(Y_train).value_counts().sort_index())\n",
        "print(f\"\\nTest label distribution:\")\n",
        "print(pd.Series(Y_test).value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Training Classification Models\n",
        "\n",
        "We'll train multiple classifiers on the transformer embeddings and compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, name, X_train, Y_train, X_test, Y_test):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {name}...\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    \n",
        "    print(f\"\\n{name} Performance:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(Y_test, Y_pred, zero_division=0))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(Y_test, Y_pred))\n",
        "    \n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define models to train\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"Support Vector Machine (Linear)\": SVC(kernel='linear', random_state=42, probability=False),\n",
        "    \"Support Vector Machine (RBF)\": SVC(kernel='rbf', random_state=42, probability=False),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    acc = train_and_evaluate(model, name, X_train, Y_train, X_test, Y_test)\n",
        "    results[name] = acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: Comparing Models to Identify the Best One"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Summary of Model Accuracies:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
        "for name, acc in sorted_results:\n",
        "    print(f\"{name}: {acc:.4f}\")\n",
        "\n",
        "best_model_name = sorted_results[0][0]\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Best Performing Model: {best_model_name}\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9: Key Advantages of Transformer-Based Classification\n",
        "\n",
        "**Why use Sentence Transformers instead of TF-IDF?**\n",
        "\n",
        "1. **Semantic Understanding**: Transformers capture meaning and context, not just word frequencies\n",
        "2. **Dense Embeddings**: 384-dimensional vectors vs sparse TF-IDF matrices (more efficient)\n",
        "3. **Pre-trained Knowledge**: Leverages knowledge learned from millions of text examples\n",
        "4. **Better Generalization**: Often performs better on unseen data\n",
        "5. **Context-Aware**: Understands word relationships and sentence structure\n",
        "\n",
        "**Comparison with Notebook 5 (TF-IDF approach):**\n",
        "- Notebook 5: Uses sparse TF-IDF features → classical ML models\n",
        "- This notebook: Uses dense transformer embeddings → classical ML models\n",
        "- Both approaches can use the same classifiers, but embeddings provide richer semantic features"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
