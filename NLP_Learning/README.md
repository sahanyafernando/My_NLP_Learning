# ğŸ““ NLP Demonstrations â€“ Notebooks & Datasets

### Overview

This folder contains Jupyter notebooks demonstrating core NLP concepts along with the
CSV datasets used in those demonstrations.
The notebooks are designed for learning, experimentation, and reference, and can be run
locally or directly in Google Colab.

### Contents
ğŸ“˜ Notebooks
  - 1_Lowercasing_StopwordRemoval_*.ipynb â€“ Basic text preprocessing
  - 2_Normalization.ipynb â€“ Unicode normalization and text standardization
  - 3_RuleBasedStemmingAndPorterStemming.ipynb â€“ Rule-based and Porter stemming
  - 4_HandlingNoisyDataAndProcessing.ipynb â€“ Cleaning noisy and real-world text
  - 5_TextClassification.ipynb â€“ Text classification fundamentals
  - 6_ConstituencyAndDependencyParsing.ipynb â€“ Syntactic parsing techniques

ğŸ“‚ Datasets
  - faq_dataset.csv
  - noisy_dataset.csv
  - sentiment_analysis.csv
  - test_dataset.csv
  - text_classification.csv

These CSV files are required to run the notebooks correctly.

### Run Notebooks Using Google Colab (Recommended)
#### Step 1: Open Notebook in Colab
Each notebook includes a â€œOpen in Colabâ€ link at the top.
You can also manually open any notebook by:
    1. Opening the .ipynb file on GitHub
    2. Clicking Open in Colab (top of the file)

#### Step 2: Upload Dataset Files
After opening the notebook in Colab:
    1. Click the folder icon on the left panel
    2. Click Upload
    3. Upload the required .csv files from this folder

ğŸ“Œ Make sure the CSV filenames remain unchanged.
Alternatively, upload all CSV files at once.

#### Step 3: Run the Notebook
  - Run cells from top to bottom
  - Ensure dataset paths match the uploaded filenames
  - No additional setup is required unless mentioned in the notebook
